{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unit3_lesson2_project6: Challenge: If a tree falls in the forest..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim: To see the improvement in accuracy provided by Random Forest over Decision Tree as well as the processing time and computing resouces trade off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: If a tree falls in the forest...\n",
    "So here's what you should do. Pick a dataset. It could be one you've worked with before or it could be a new one. Then build the best decision tree you can.\n",
    "\n",
    "Now try to match that with the simplest random forest you can. For our purposes measure simplicity with runtime. Compare that to the runtime of the decision tree. This is imperfect but just go with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0           1        337          118                  4  4.5  4.5  9.65   \n",
       "1           2        324          107                  4  4.0  4.5  8.87   \n",
       "2           3        316          104                  3  3.0  3.5  8.00   \n",
       "3           4        322          110                  3  3.5  2.5  8.67   \n",
       "4           5        314          103                  2  2.0  3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit  \n",
       "0         1             0.92  \n",
       "1         1             0.76  \n",
       "2         1             0.72  \n",
       "3         1             0.80  \n",
       "4         0             0.65  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datasource:'https://www.kaggle.com/mohansacharya/graduate-admissions#Admission_Predict.csv'\n",
    "PATH = 'unit3_data/Admission_Predict.csv'\n",
    "data_raw = pd.read_csv(PATH)\n",
    "\n",
    "#there seem to be issues with the col name, they contain trialing spaces, let's remove that and re-append them by\n",
    "#first extracting the cols as a list, clean up each item and the appent the new list as cols. I will encapsulate this into \n",
    "#a function.\n",
    "def clean_columns(dirty_data):\n",
    "    col_lst = (dirty_data.columns)\n",
    "    #strip the trailing spaces\n",
    "    col_lst_new = []\n",
    "    for element in col_lst:\n",
    "        col_lst_new.append(element.strip())\n",
    "    #append new headers\n",
    "    dirty_data.columns = col_lst_new\n",
    "    return dirty_data\n",
    "\n",
    "data_raw = clean_columns(data_raw)\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#drop serial number and the outcome variable, then scale this data for proper fit for PCA\n",
    "Y = data_raw['Chance of Admit']\n",
    "data_raw.drop(['Serial No.', 'Chance of Admit'], 1, inplace=True)\n",
    "sc = StandardScaler()\n",
    "data_raw_scaled = sc.fit_transform(data_raw)\n",
    "#convert back to df\n",
    "data_raw_scaled = pd.DataFrame(data_raw_scaled, columns=data_raw.columns)\n",
    "X = data_raw_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pca = PCA() #let's start off with all components, we will come back to include n_compositions as required\n",
    "pca = PCA(n_components=5) #this number was determine after running all the components and calculating the variance expalined\n",
    "X_comp = pca.fit_transform(X)\n",
    "\n",
    "#calculation the number of required components\n",
    "def optimun_no_comp(explained_variance):\n",
    "    cumsum = 0\n",
    "    i = 0\n",
    "    while cumsum<=0.95:\n",
    "        cumsum+=explained_variance[i]\n",
    "        i+=1\n",
    "    return(i)\n",
    "\n",
    "optimun_no_comp(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now data we have our data in the right form, we will start off our modelling first with a very basic DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56084798, 0.37900474, 0.44942461, 0.4461793 , 0.25302861,\n",
       "       0.43428614, 0.55729724, 0.61811822, 0.57086648, 0.69982584])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import ensemble(to aid comination of models) and cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# import the regressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#implement decision tree regression  \n",
    "# first create a regressor object \n",
    "regressor = DecisionTreeRegressor(random_state = 0) \n",
    "\n",
    "#run decision tree regressor model\n",
    "cross_val_score(regressor, X_comp, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As can be seen from the result above, our Decision Tree is very basic with `random_state of 0`. The accuracy is very terrible with large variance(Highest accuracy and lowest are 70 and 25% respectively). In the following segment, we will build an RF with the same trianing data and see how our simple decision tree compares with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73403998, 0.57036381, 0.65451054, 0.57139623, 0.71284993,\n",
       "       0.74140048, 0.79711909, 0.82345377, 0.52031622, 0.77881303])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestRegressor()\n",
    "cross_val_score(rfc, X_comp, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This result is not impressive, RF should have far better accuracy than DT, the variance in accuracy did not improve as well as we moved from DT to RF. The possible issue might be because there only a few observation in this dataset, just arrouns four hundre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data\n",
    "data_2 = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/master/ESS_practice_data/ESSdata_Thinkful.csv')\n",
    "\n",
    "#we can freely dropna here, since our data is quite huge\n",
    "data_2.dropna(inplace=True)\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's get rid of irrelevant columns and then apply PCA\n",
    "data_2.drop(['idno'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "      <th>cntry_CH</th>\n",
       "      <th>cntry_CZ</th>\n",
       "      <th>cntry_DE</th>\n",
       "      <th>cntry_ES</th>\n",
       "      <th>cntry_NO</th>\n",
       "      <th>cntry_SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tvtot  ppltrst  pplfair  pplhlp  sclmeet  sclact  gndr  agea  \\\n",
       "0     6    3.0      3.0     10.0     5.0      5.0     4.0   2.0  60.0   \n",
       "1     6    6.0      5.0      7.0     5.0      3.0     2.0   2.0  59.0   \n",
       "2     6    1.0      8.0      8.0     8.0      6.0     3.0   1.0  24.0   \n",
       "3     6    4.0      6.0      6.0     7.0      6.0     2.0   2.0  64.0   \n",
       "4     6    5.0      6.0      7.0     5.0      7.0     2.0   2.0  55.0   \n",
       "\n",
       "   partner  cntry_CH  cntry_CZ  cntry_DE  cntry_ES  cntry_NO  cntry_SE  \n",
       "0      1.0         1         0         0         0         0         0  \n",
       "1      1.0         1         0         0         0         0         0  \n",
       "2      2.0         1         0         0         0         0         0  \n",
       "3      1.0         1         0         0         0         0         0  \n",
       "4      1.0         1         0         0         0         0         0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#netxt we will seperate X and Y\n",
    "Y2 = data_2['happy']\n",
    "X2 = data_2.drop(['happy'], 1)\n",
    "\n",
    "#neither pca nor RF can handle strings , so let's convert the countary categorical variable using 1 hot code of get_dummies.\n",
    "X2 = pd.get_dummies(X2)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's satandardize X2 and then view it correllation matrix with heatmap\n",
    "X2_stdze = sc.fit_transform(X2)\n",
    "\n",
    "#let see how X2_stdze looks on heatmap\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "#first we need to revert back to df as corr doesnt work with arrays\n",
    "ax = sns.heatmap((pd.DataFrame(X2_stdze).corr()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seems like we have quit a lot of correllation, we will use PCA to resolve them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15936499, 0.09705255, 0.08292578, 0.08249282, 0.0784293 ,\n",
       "       0.06618222, 0.06399571, 0.06318974, 0.06140698, 0.0556144 ,\n",
       "       0.05354934, 0.04174431, 0.03505653, 0.03424201])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create another PCA object\n",
    "pca2 = PCA(0.95)\n",
    "\n",
    "#appply pca to X2\n",
    "X2_comp = pca2.fit_transform(X2_stdze)\n",
    "pca2.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are now set to run our model on these data. But we need to remember that Y2 is categorical so we can invoke the right method from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23536585, 0.18459658, 0.13096695, 0.18014706, 0.19018405,\n",
       "       0.17567568, 0.17589176, 0.19211823, 0.23427867, 0.22194821])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's import our classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#creat a classifier object\n",
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#we will implement this using the cross_val_score method from sklearn.modelselection\n",
    "cross_val_score(classifier, X2_comp, Y2, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.27317073, 0.20904645, 0.13341493, 0.15318627, 0.21717791,\n",
       "       0.18918919, 0.20787208, 0.2044335 , 0.23797781, 0.25893958])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We do not need to import RF classifier as it is available through ensemble\n",
    "\n",
    "#creat a classifier object\n",
    "rfc2 = ensemble.RandomForestClassifier()\n",
    "\n",
    "cross_val_score(rfc2, X2_comp, Y2, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: As expected, the accuracy of the RF model substantially exceeded that of the the DT for the two data used in this project. Meanwhile the overall accuracy of the models are way too low (particularly for the second data), I'm not sure if this has something to do with the sort of data I used or if I'm doing something wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
