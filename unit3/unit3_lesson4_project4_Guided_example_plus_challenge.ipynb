{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 3 Lesson 4 Project 4: Guided example + challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for another guided example. This time we're going to look at recipes. Specifically we'll use the epicurious dataset, which has a collection of recipes, key terms and ingredients, and their ratings.\n",
    "\n",
    "What we want to see is if we can use the ingredient and keyword list to predict the rating. For someone writing a cookbook this could be really useful information that could help them choose which recipes to include because they're more likely to be enjoyed and therefore make the book more likely to be successful.\n",
    "\n",
    "First let's load the dataset. It's available on Kaggle. We'll use the csv file here and as pull out column names and some summary statistics for ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'unit3_data/recipes_unit3_less4_project4_SCV.csv'\n",
    "raw_data = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20052.000000\n",
       "mean         3.714467\n",
       "std          1.340829\n",
       "min          0.000000\n",
       "25%          3.750000\n",
       "50%          4.375000\n",
       "75%          4.375000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what the distribution of rstings look like\n",
    "raw_data.rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn a few things from this analysis. From a ratings perspective, there are just over 20,000 recipes with an average rating of 3.71. What is interesting is that the 25th percentile is actually above the mean. This means there is likely some kind of outlier population. This makes sense when we think about reviews: some bad recipes may have very few very low reviews.\n",
    "\n",
    "Let's validate the idea a bit further with a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.rating.hist(bins=20)\n",
    "plt.title('Histogram of Recipe Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a few things are shown in this histogram. Firstly there are sharp discontinutities. We don't have continuous data. No recipe has a 3.5 rating, for example. Also we see the anticipated increase at 0.\n",
    "\n",
    "Let's try a naive approach again, this time using SVM Regressor. But first, we'll have to do a bit of data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories    4117\n",
       "protein     4162\n",
       "fat         4183\n",
       "sodium      4119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nulls \n",
    "null_count = raw_data.isnull().sum()\n",
    "null_count[null_count>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can see right away is that nutrition information is not available for all goods. Now this would be an interesting data point, but let's focus on ingredients and keywords right now. So we'll actually drop the whole columns for calories, protein, fat, and sodium. We'll come back to nutrition information later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "X = raw_data.drop(['rating', 'title', 'calories', 'protein', 'fat', 'sodium'], 1)\n",
    "Y = raw_data.rating\n",
    "#svr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note that this actually takes quite a while to run, compared to some of the models we've done before. Be patient.__ It's because of the number of features we have.\n",
    "\n",
    "Let's see what a scatter plot looks like, comparing actuals to predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(Y, svr.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that is a pretty useless visualization. This is because of the discontinous nature of our outcome variable. There's too much data for us to really see what's going on here. If you wanted to look at it you could create histograms, here we'll move on to the scores of both our full fit model and with cross validation. Again if you choose to run it again it will take some time, so you probably shouldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svr.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#cross_val_score(svr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear, so this did seem not to work very well. In fact it is remarkably poor. Now there are many things that we could do here. \n",
    "\n",
    "Firstly the overfit is a problem, even though it was poor in the first place. We could go back and clean up our feature set. There might be some gains to be made by getting rid of the noise.\n",
    "\n",
    "We could also see how removing the nulls but including dietary information performs. Though its a slight change to the question we could still possibly get some improvements there.\n",
    "\n",
    "Lastly, we could take our regression problem and turn it into a classifier. With this number of features and a discontinuous outcome, we might have better luck thinking of this as a classification problem. We could make it simpler still by instead of classifying on each possible value, group reviews to some decided high and low values.\n",
    "\n",
    "__And that is your challenge.__\n",
    "\n",
    "Transform this regression problem into a binary classifier and clean up the feature set. You can choose whether or not to include nutritional information, but try to cut your feature set down to the 30 most valuable features.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've finished that, also take a moment to think about bias. Is there anything in this dataset that makes you think it could be biased, perhaps extremely so?\n",
    "\n",
    "There is. Several things in fact, but most glaringly is that we don't actually have a random sample. It could be, and probably is, that the people more likely to choose some kinds of recipes are more likely to give high reviews.\n",
    "\n",
    "After all, people who eat chocolate _might_ just be happier people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before looking into other feature engineering, I will first categorize the outcome variable into 10 categories at step 0.5 \n",
    "#and then implement an SVC classifier with the raw features as we did with the regressor.\n",
    "target = raw_data.rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize outcoume variable in preparation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(0.0, 5.5, 0.5)\n",
    "\n",
    "#the lable below did not work as outcome variable, I realised that for SCV, the outcome variable must be number not text\n",
    "label_old=['0 to 0.499', \n",
    "       '0.5-0.999',\n",
    "       '1.0-1.499',\n",
    "       '1.5-1.999',\n",
    "       '2.0-2.499',\n",
    "       '2.5-2.999',\n",
    "       '3.0-3.499',\n",
    "       '3.5-3.999',\n",
    "       '4.0-4.499',\n",
    "       '4.5-5.0']\n",
    "label = [0.0, 0.5, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0] \n",
    "Y_cat = pd.cut(raw_data.rating, bins=steps, include_lowest=True, labels=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement SCV and via cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-af8996663c15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    148\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                          accept_large_sparse=False)\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    169\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    170\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "\n",
    "cross_val_score(svc, X, Y_cat, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I still do not know why this is not working, probably SVC only works with 2 categories only. While still trying to figure things out, I will try a simpler version by just categorizing the ratings into low and high. Low will be represented by 0 with ratings ranging from 0-2.5, while high will be ratings above 2.5 and represented as 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86739781, 0.86758105, 0.86758105, 0.86758105, 0.86758105])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#categorize target and run SVC\n",
    "Y_cat2 = np.where(target<=2.5, 1, 0)\n",
    "cross_val_score(svc, X, Y_cat2, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bingo! This works, but I'm not sure if there's overfitting. I migth try again with multiple categries above but using 1-hot-encoding. For now I will use PCA to extract the best 30 out of the raw features in the data and see if anything will change**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This classification is not impressive as well. I will used PCA to extract the best 30 out of the raw features and see if this will lead to an improvement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12310325 0.04414084 0.03883227 0.02648318 0.02280018 0.01867339\n",
      " 0.01624925 0.01510961 0.01430329 0.01340297 0.01245194 0.01186382\n",
      " 0.01149495 0.0103183  0.01002494 0.00932866 0.00909628 0.00888394\n",
      " 0.00867696 0.00839832 0.00821625 0.00809792 0.0077656  0.0076928\n",
      " 0.00756076 0.00724669 0.00712169 0.00702149 0.00683106 0.00675264]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20052, 30)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87288136, 0.87506234, 0.8765586 , 0.87381546, 0.87531172])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc, X_pca, Y_cat2, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wow! Things have really improved in terms of our model score and it variance over 5 folds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now one-hot-encoding for the multi-categorical model and see if we would be lucky to have it run. Remenber our Y is `Y_cat`. This time arround we will use the decomposed X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.5</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>3.0</th>\n",
       "      <th>3.5</th>\n",
       "      <th>4.0</th>\n",
       "      <th>4.5</th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  0.5  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0\n",
       "0    0    0    0    0    1    0    0    0    0    0\n",
       "1    0    0    0    0    0    0    0    0    1    0\n",
       "2    0    0    0    0    0    0    0    1    0    0\n",
       "3    0    0    0    0    0    0    0    0    0    1\n",
       "4    0    0    0    0    0    0    1    0    0    0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dummy for label_old\n",
    "Y_cat_encoded = pd.get_dummies(Y_cat)\n",
    "Y_cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20052, 10)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_cat_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-c9270bcd4b19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#run the SVC model again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_cat_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "#run the SVC model again\n",
    "cross_val_score(svc, X)\n",
    "cross_val_score(svc, X_pca, Y_cat_encoded, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now this is really bad, SCV could identy a y in our model, I think was expecting a single col y. Does this mean that SCV cannot be used for multinomial classification?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see if introducing `gamma` would help our SVC scale through multinomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (20052, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-3577524ba9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'scale'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_cat_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    148\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    759\u001b[0m                         dtype=None)\n\u001b[0;32m    760\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (20052, 10)"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='scale')\n",
    "clf.fit(X, Y_cat_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/svm.html - will need to read through this documentation at a later time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
