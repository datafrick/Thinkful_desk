{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit3_Lesson6_Project1: Credit Card Fraud\n",
    "Data Source: https://www.kaggle.com/mlg-ulb/creditcardfraud<br>\n",
    "**Question:** Using this credit card fraud dataset, develop an algorithm to predict fraud. Prioritize correctly finding fraud rather than correctly labeling non-fraudulent transactions. In the outcome column(Class), 1 signifies fraud while zero is the reverse.\n",
    "\n",
    "Note: There's is no much visibility into this dataset as it has been processed already with PCA. I'm just going to go straight into modelling the predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  First I will use decision tree to classify the data, then employ bagging technique using Random Forest.\n",
    "-  I will then use logistic regression to see if there will be any disparity.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data, create a dataframe and split into dependent/independent variables\n",
    "PATH = 'unit3_data/creditcard_fraud.csv'\n",
    "data = pd.read_csv(PATH)\n",
    "\n",
    "#data into X and Y\n",
    "Y = data.Class\n",
    "#X = data.loc[:,'Time':'Amount']\n",
    "X = data.loc[:, ~data.columns.isin(['Class'])]\n",
    "\n",
    "#split data into train-test using ration 9:1\n",
    "offset = int(X.shape[0]*0.9)\n",
    "x_train, x_test = X[: offset], X[offset :]\n",
    "y_train, y_test = Y[: offset], Y[offset :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will create a function to run models and output their accuracy. In terms of accuracy, I will focuse more on  `Type 1 Error` (i.e labelling `fraud` as `non-fraud`) and try to minimize this error as much as possible. In each modelling case I will evaluate errors for both training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for running model \n",
    "def run_model(model, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    # Initialize and fit the model.\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    #predict training and test data\n",
    "    predict_train = model.predict(x_train)\n",
    "    predict_test = model.predict(x_test)\n",
    "    \n",
    "    # creat accuracy tables for trian and test predictions\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "    \n",
    "    #generate Type-I and Type-II errors rates for training data predictions\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "    \n",
    "    #generate Type-I and Type-II errors rates for testing data predictions\n",
    "    test_tI_errors = table_test.loc[0.0,1.0] / table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0] / table_test.loc['All','All']\n",
    "    \n",
    "    #output accuracies\n",
    "    print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First let's run DT with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0005266669007408447\n",
      "Percent Type II errors: 0.00028088901372845055\n"
     ]
    }
   ],
   "source": [
    "#create model with default parameters\n",
    "dtm_default = DecisionTreeClassifier()\n",
    "\n",
    "#run model in our customized function\n",
    "run_model(dtm_default, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is a very good result, let's see if we can make it  better by specifying some key parameters in our DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0004330422976990239\n",
      "Percent Type II errors: 0.000542278192614093\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0001755556335802816\n",
      "Percent Type II errors: 0.0003862223938766195\n"
     ]
    }
   ],
   "source": [
    "#set some important three performace parameters.\n",
    "#Due to the class in balance in ths dataset one very important parameter that must be \n",
    "#set for this data is `min_samples_split`. The value should normally be 0.5-1% all observationsin a balance class case\n",
    "#here I will use 0.25% \n",
    "params = {'criterion':'gini', \n",
    "         'max_depth':8,\n",
    "         'max_features':int(math.sqrt(len(X.columns))),\n",
    "         'min_samples_split':int(0.0025*len(X))\n",
    "        }\n",
    "\n",
    "dtm_params = DecisionTreeClassifier(**params)\n",
    "run_model(dtm_params, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see a significant improvement in `Type-I-Error` here from `0.0005617780274569011` to `0.0001755556335802816`. Although performance dropped a little in terms of `Type-II-Error` but this is not our focus, we only need to be sure the value is decent(of which what we have is more than decent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will used BGM to iterate over several trees for further improvement of this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model\n",
    "Here I will retain all the tree parameters I applied above for the DT. In optimizing the GBM, my parameter of focus is the `n_estimators`. So I will choosing a relatively high `learning_rate` (which I can reduce later), choose a `subsample` value of 0.8 for each tree and then run `GridSearch` to obtain the optimum `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn.model_selection import cross_val_score   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "               max_features='sqrt', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=712,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "               n_iter_no_change=None, presort='auto', random_state=10,\n",
       "               subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " {'n_estimators': 20},\n",
       " 0.86727666910062)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test = param_test2 = {'n_estimators':range(20,81,10)}\n",
    "gsearch = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                     min_samples_split=int(0.0025*len(X)),\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10), param_grid = param_test, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(x_train,y_train)\n",
    "gsearch.best_estimator_, gsearch.best_params_, gsearch.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see, the optimum `n_estimator` is 20, the model score at this values is also quite good. The n_estimator value along with other parameters mentioned above will now be used to create our GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0003238064027839548\n",
      "Percent Type II errors: 0.0007958615200955034\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.00028088901372845055\n",
      "Percent Type II errors: 0.0004915557740247885\n"
     ]
    }
   ],
   "source": [
    "#Create GBM model\n",
    "gbm = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                     min_samples_split=int(0.0025*len(X)),\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10,\n",
    "                                     n_estimators=20)\n",
    "#run model in our customized function\n",
    "run_model(gbm, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This result is not impressive, infact the `type-I-Error` is worse off compared to our tuned DT above. May be we should have ran another `GridSearch` while cutting back on the staring value of our `n_estimators` with say range(5,20,5). Be that as it may, I will process with the same model while reducing our `learning_rate` to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.00178678713825363\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0007022225343211264\n"
     ]
    }
   ],
   "source": [
    "#Create GBM model\n",
    "gbm = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                     min_samples_split=int(0.0025*len(X)),\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10,\n",
    "                                     n_estimators=20)\n",
    "#run model in our customized function\n",
    "run_model(gbm, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bingo! Our `Type-I-Error` has now reduced to zero, this is like getting more that what you bargained for. This model if deployed will have almost 100% accuracy in identify fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
